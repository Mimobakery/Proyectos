{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción del proyecto\n",
    "\n",
    "El proyecto tiene como objetivo desarrollar un modelo predictivo para recomendar el plan adecuado (Smart o Ultra) a los clientes de Megaline, basado en su comportamiento mensual. Utilizando datos como el número de llamadas, mensajes y tráfico de datos, se entrenarán modelos de clasificación como Regresión Logística, Árbol de Decisión y Random Forest. El modelo deberá alcanzar una exactitud mínima del 75% para predecir correctamente el plan, ayudando a la empresa a optimizar su estrategia comercial y mejorar la satisfacción del cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desarrollo:\n",
    "#### Paso 1: Cargar librerías y explorar dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carga de librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score  \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"/datasets/users_behavior.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "\n",
      "0\n",
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# se usan las funciones info y head para inspección de la información  del dataset\n",
    "users.info()\n",
    "print(users.head())\n",
    "print()\n",
    "#revisión de filas duplicadas\n",
    "print(users.duplicated().sum())\n",
    "#revisión valores ausentes \n",
    "print(users.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se cambia el tipo de dato a entero\n",
    "users['is_ultra'] = users['is_ultra'].astype(int)\n",
    "users['messages'] = users['messages'].astype(int)\n",
    "users['calls'] = users['calls'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 2: Dividir el dataset en conjuntos de entrenamiento, validación y prueba\n",
    "\n",
    "El conjunto de prueba no existe, por lo que los datos fuente deben dividirse en tres partes: entrenamiento, validación y prueba. Usualmente, el tamaño del conjunto de validación y el de prueba son iguales. Esto da como resultado una proporción de datos fuente de 3:1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se divide el df total en conjunto de prueba y mix (60%-40%)\n",
    "users_train, users_mix = train_test_split(users, test_size=0.4, random_state=12345)\n",
    "\n",
    "# se divide el conjunto mix en prueba y validación (50%-50%)\n",
    "users_valid, users_test = train_test_split(users_mix, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se separan las características (features) y la variable objetivo (target),se revisan mediante print\n",
    "features_train = users_train.drop(['is_ultra'], axis=1)\n",
    "target_train = users_train['is_ultra']\n",
    "features_valid = users_valid.drop(['is_ultra'], axis=1) \n",
    "target_valid = users_valid['is_ultra'] \n",
    "features_test = users_test.drop(['is_ultra'], axis=1) \n",
    "target_test = users_test['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 4)\n",
      "(1928,)\n",
      "(643, 4)\n",
      "(643,)\n",
      "(643, 4)\n",
      "(643,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 3: Definir y entrenar los modelos\n",
    "\n",
    "En esta sección, se definen y entrenan tres modelos: Árbol de Decisión, Regresión Logística y Random Forest. El Árbol de Decisión realiza predicciones dividiendo los datos en función de características clave, la Regresión Logística es un modelo lineal utilizado para clasificación binaria y el Random Forest (Bosque aleatorio) es un modelo de ensamblaje que combina varios árboles de decisión para mejorar la precisión. Todos los modelos serán entrenados con los datos de entrenamiento para ajustar sus parámetros y hacer predicciones en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Árbol de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.7542768273716952\n",
      "max_depth = 2 : 0.7822706065318819\n",
      "max_depth = 3 : 0.7853810264385692\n",
      "max_depth = 4 : 0.7791601866251944\n"
     ]
    }
   ],
   "source": [
    "best_depth = None\n",
    "best_accuracy = 0\n",
    "\n",
    "# se prueban diferentes profundidades\n",
    "for depth in range(1, 5):\n",
    "        model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "        model.fit(features_train, target_train)\n",
    "\n",
    "        predictions_valid = model.predict(features_valid)\n",
    "        # se calcula la exactitud en el conjunto de validación\n",
    "        accuracy = accuracy_score(target_valid, predictions_valid)\n",
    "\n",
    "        print(\"max_depth =\", depth, \": \", end='')\n",
    "        print(accuracy)\n",
    "        \n",
    "        # se guarda la mejor puntuación de accuracy y depth en el conjunto de validación\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_depth = depth\n",
    "            best_model = model # se guarda el mejor modelo\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo de regresión logística en el conjunto de entrenamiento: 0.7505186721991701\n",
      "Accuracy del modelo de regresión logística en el conjunto de validación: 0.7589424572317263\n"
     ]
    }
   ],
   "source": [
    "best_model2 = LogisticRegression(random_state=12345, solver='liblinear') # se usa liblinear ya que es apropiada para problemas binarios y conjuntos de datos pequeños\n",
    "best_model2.fit(features_train, target_train) \n",
    "score_train = best_model2.score(features_train, target_train) # se calcula la puntuación de accuracy en el conjunto de entrenamiento\n",
    "score_valid = best_model2.score(features_valid, target_valid) # se calcula la puntuación de accuracy en el conjunto de validación\n",
    "\n",
    "print(\"Accuracy del modelo de regresión logística en el conjunto de entrenamiento:\", score_train)\n",
    "print(\"Accuracy del modelo de regresión logística en el conjunto de validación:\", score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del mejor modelo en el conjunto de validación (n_estimators = 23): 0.7947122861586314\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "best_model3 = None\n",
    "\n",
    "\n",
    "for est in range(1, 25): # se selecciona el rango del hiperparámetro para n_estimators\n",
    "    model3 = RandomForestClassifier(random_state=12345, n_estimators=est) # se configura el número de árboles\n",
    "    model3.fit(features_train, target_train) \n",
    "    score = model3.score(features_valid, target_valid) # calcula la puntuación de accuracy en el conjunto de validación\n",
    "    \n",
    "    # guarda la mejor puntuación de accuracy y el número de estimadores correspondientes en el conjunto de validación\n",
    "    if score > best_score:\n",
    "        best_score = model3.score(features_valid, target_valid) \n",
    "        best_est = est \n",
    "        best_model3 = model3  # se guarda el mejor modelo\n",
    "\n",
    "\n",
    "\n",
    "print(\"La exactitud del mejor modelo en el conjunto de validación (n_estimators = {}): {}\".format(best_est, best_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 4: Evaluar los modelos en el conjunto de prueba\n",
    "\n",
    "En esta fase, se evaluará el rendimiento de los modelos entrenados en el conjunto de prueba para medir su capacidad de generalización. Utilizando la exactitud como métrica, se compararán las predicciones de los modelos de Árbol de Decisión, Regresión Logística y Random Forest con las respuestas reales del conjunto de prueba. Esto nos permitirá identificar cuál de los modelos tiene el mejor desempeño en datos no vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en prueba (Árbol de Decisión): 0.7792\n",
      "Exactitud en prueba (Regresión Logística): 0.7403\n",
      "Exactitud en prueba (Random Forest): 0.7807\n"
     ]
    }
   ],
   "source": [
    "# se evalua el modelo de árbol de decisión en el conjunto de prueba\n",
    "y_test_ad = best_model.predict(features_test)\n",
    "accuracy_test_dt = accuracy_score(target_test, y_test_ad)\n",
    "print(f'Exactitud en prueba (Árbol de Decisión): {accuracy_test_dt:.4f}')\n",
    "\n",
    "# se evalua el modelo de regresión logística en el conjunto de prueba\n",
    "y_test_rl = best_model2.predict(features_test)\n",
    "accuracy_test_log_reg = accuracy_score(target_test, y_test_rl)\n",
    "print(f'Exactitud en prueba (Regresión Logística): {accuracy_test_log_reg:.4f}')\n",
    "\n",
    "# se evalua el modelo de Random Forest en el conjunto de prueba\n",
    "y_test_bd = best_model3.predict(features_test)\n",
    "accuracy_test_rf = accuracy_score(target_test, y_test_bd)\n",
    "print(f'Exactitud en prueba (Random Forest): {accuracy_test_rf:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest es el modelo que tiene la mejor calidad en términos de exactitud en el conjunto de prueba con un 78.07%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 5: Tarea adicional  (prueba de cordura al modelo)\n",
    "\n",
    "Se realizará una validación cruzada con el fin de evaluar el rendimiento del modelo de manera más robusta y confiable. Este proceso divide el conjunto de datos en varios pliegues, entrenando y evaluando el modelo en cada uno de ellos, lo que permite obtener una estimación más precisa de su capacidad de generalización. \n",
    "\n",
    "Además, se llevará a cabo una comprobación de sobreajuste comparando la precisión entre el conjunto de entrenamiento y el conjunto de prueba. Esto nos ayudará a detectar si el modelo está ajustándose excesivamente a los datos de entrenamiento (sobreajuste) o si no está capturando bien los patrones en los datos (subajuste). Ambas técnicas son esenciales para garantizar que el modelo sea estable y capaz de generalizar a nuevos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntajes de validación cruzada: [0.79782271 0.76205288 0.79937792 0.78693624 0.80218069]\n",
      "Media de la validación cruzada: 0.7897\n"
     ]
    }
   ],
   "source": [
    "features = users.drop(['is_ultra'], axis=1)\n",
    "target = users['is_ultra']\n",
    "\n",
    "# Realizar validación cruzada\n",
    "cv_scores = cross_val_score(best_model3, features, target, cv=5)\n",
    "print(f'Puntajes de validación cruzada: {cv_scores}')\n",
    "print(f'Media de la validación cruzada: {cv_scores.mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada nos indica que el modelo generalmente está funcionando bien y tiene un rendimiento estable en todos los pliegues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en prueba (Random Forest): 0.7807\n",
      "Exactitud en entrenamiento (Random Forest): 0.9938\n"
     ]
    }
   ],
   "source": [
    "# comparación entre precisión en entrenamiento y prueba\n",
    "y_train_pred = best_model3.predict(features_train)\n",
    "accuracy_train_rf = accuracy_score(target_train, y_train_pred)\n",
    "print(f'Exactitud en prueba (Random Forest): {accuracy_test_rf:.4f}')\n",
    "print(f'Exactitud en entrenamiento (Random Forest): {accuracy_train_rf:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La comparación nos indica que el modelo está sobreajustado, lo que significa que el modelo ha \"memorizado\" demasiado bien los datos de entrenamiento y no está generalizando correctamente a nuevos datos. Según lo investigado, esto suele suceder cuando el modelo es demasiado complejo o no está regularizado adecuadamente. Algunas estrategias que se puede aplicar en el futuro para mejorar el modelo y reducir el ajuste son las siguientes:\n",
    "1. Reducir la complejidad del modelo\n",
    "2. Usar Regularización\n",
    "3. Aumentar los datos de entrenamiento\n",
    "4. Early Stopping \n",
    "5. Entrenar con más datos representativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "El proyecto logró desarrollar un modelo predictivo eficaz para recomendar el plan adecuado (Smart o Ultra) a los clientes de Megaline, basado en su comportamiento mensual. A través de la implementación y evaluación de tres modelos de clasificación: Árbol de Decisión, Regresión Logística y Random Forest, se logró identificar que el modelo de Random Forest presentó el mejor desempeño con una exactitud del 78.07% en el conjunto de prueba. \n",
    "\n",
    "Durante el proceso, se implementaron técnicas como la validación cruzada y la comprobación de sobreajuste, lo que permitió obtener una estimación más robusta del rendimiento del modelo y detectar que el modelo de Random Forest estaba sobreajustado. Este sobreajuste sugiere que el modelo ha memorizado demasiado los datos de entrenamiento, lo que limita su capacidad de generalizar a nuevos datos. Se sugirieron varias estrategias, como reducir la complejidad del modelo y aumentar los datos de entrenamiento, para mejorar la capacidad de generalización en el futuro. En general, el proyecto proporciona una base sólida para la toma de decisiones en Megaline, con la posibilidad de seguir optimizando los modelos para mejorar aún más su precisión y desempeño.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 863,
    "start_time": "2024-11-20T02:14:45.764Z"
   },
   {
    "duration": 10,
    "start_time": "2024-11-20T02:16:34.843Z"
   },
   {
    "duration": 14,
    "start_time": "2024-11-20T02:16:49.826Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-20T02:17:18.442Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-20T02:18:20.979Z"
   },
   {
    "duration": 15,
    "start_time": "2024-11-20T02:18:31.912Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-20T02:19:10.378Z"
   },
   {
    "duration": 25,
    "start_time": "2024-11-20T02:20:30.315Z"
   },
   {
    "duration": 23,
    "start_time": "2024-11-20T02:21:16.999Z"
   },
   {
    "duration": 1128,
    "start_time": "2024-11-20T02:22:08.992Z"
   },
   {
    "duration": 19,
    "start_time": "2024-11-20T02:22:53.800Z"
   },
   {
    "duration": 543,
    "start_time": "2024-11-20T02:24:13.873Z"
   },
   {
    "duration": 14,
    "start_time": "2024-11-20T02:24:51.008Z"
   },
   {
    "duration": 776,
    "start_time": "2024-11-20T20:35:28.266Z"
   },
   {
    "duration": 13,
    "start_time": "2024-11-20T20:35:29.045Z"
   },
   {
    "duration": 18,
    "start_time": "2024-11-20T20:35:29.062Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-20T20:35:29.082Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-20T20:35:29.090Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-20T20:35:29.097Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-20T20:35:29.105Z"
   },
   {
    "duration": 22,
    "start_time": "2024-11-20T20:35:29.110Z"
   },
   {
    "duration": 45,
    "start_time": "2024-11-20T20:35:29.134Z"
   },
   {
    "duration": 1033,
    "start_time": "2024-11-20T20:35:29.181Z"
   },
   {
    "duration": 12,
    "start_time": "2024-11-20T20:35:30.216Z"
   },
   {
    "duration": 496,
    "start_time": "2024-11-20T20:35:30.231Z"
   },
   {
    "duration": 11,
    "start_time": "2024-11-20T20:35:30.729Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
